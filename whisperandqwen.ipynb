{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba9cbe0b-1e52-44d3-a89a-f45ee4157fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai-whisper\n",
      "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
      "     ---------------------------------------- 0.0/803.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/803.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/803.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/803.2 kB ? eta -:--:--\n",
      "     ------------- -------------------------- 262.1/803.2 kB ? eta -:--:--\n",
      "     ------------- -------------------------- 262.1/803.2 kB ? eta -:--:--\n",
      "     ------------- -------------------------- 262.1/803.2 kB ? eta -:--:--\n",
      "     ----------------------- ------------ 524.3/803.2 kB 493.7 kB/s eta 0:00:01\n",
      "     ----------------------- ------------ 524.3/803.2 kB 493.7 kB/s eta 0:00:01\n",
      "     --------------------------------------- 803.2/803.2 kB 567.7 kB/s  0:00:01\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting more-itertools (from openai-whisper)\n",
      "  Downloading more_itertools-10.7.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting numba (from openai-whisper)\n",
      "  Downloading numba-0.61.2-cp312-cp312-win_amd64.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy in c:\\program files\\python312\\lib\\site-packages (from openai-whisper) (2.2.6)\n",
      "Collecting tiktoken (from openai-whisper)\n",
      "  Downloading tiktoken-0.11.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: torch in c:\\program files\\python312\\lib\\site-packages (from openai-whisper) (2.7.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pal\\appdata\\roaming\\python\\python312\\site-packages (from openai-whisper) (4.65.2)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba->openai-whisper)\n",
      "  Downloading llvmlite-0.44.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken->openai-whisper)\n",
      "  Downloading regex-2025.7.34-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\pal\\appdata\\roaming\\python\\python312\\site-packages (from tiktoken->openai-whisper) (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\program files\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pal\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.7.14)\n",
      "Requirement already satisfied: filelock in c:\\users\\pal\\appdata\\roaming\\python\\python312\\site-packages (from torch->openai-whisper) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\program files\\python312\\lib\\site-packages (from torch->openai-whisper) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\program files\\python312\\lib\\site-packages (from torch->openai-whisper) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\program files\\python312\\lib\\site-packages (from torch->openai-whisper) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\program files\\python312\\lib\\site-packages (from torch->openai-whisper) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\program files\\python312\\lib\\site-packages (from torch->openai-whisper) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pal\\appdata\\roaming\\python\\python312\\site-packages (from torch->openai-whisper) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\program files\\python312\\lib\\site-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\program files\\python312\\lib\\site-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
      "Requirement already satisfied: colorama in c:\\program files\\python312\\lib\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
      "Downloading more_itertools-10.7.0-py3-none-any.whl (65 kB)\n",
      "Downloading numba-0.61.2-cp312-cp312-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.8 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.8 MB 699.0 kB/s eta 0:00:04\n",
      "   ------- -------------------------------- 0.5/2.8 MB 699.0 kB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 0.8/2.8 MB 729.2 kB/s eta 0:00:03\n",
      "   -------------- ------------------------- 1.0/2.8 MB 799.2 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 1.3/2.8 MB 808.5 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 1.3/2.8 MB 808.5 kB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 1.6/2.8 MB 856.1 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 2.1/2.8 MB 962.8 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.4/2.8 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.6/2.8 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.8/2.8 MB 1.1 MB/s  0:00:02\n",
      "Downloading llvmlite-0.44.0-cp312-cp312-win_amd64.whl (30.3 MB)\n",
      "   ---------------------------------------- 0.0/30.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/30.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/30.3 MB 2.1 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 1.0/30.3 MB 1.9 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 1.3/30.3 MB 1.6 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 1.8/30.3 MB 1.9 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 2.4/30.3 MB 2.0 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 2.9/30.3 MB 2.1 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 3.4/30.3 MB 2.2 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 4.2/30.3 MB 2.3 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 4.7/30.3 MB 2.4 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 5.5/30.3 MB 2.4 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 6.0/30.3 MB 2.5 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 6.8/30.3 MB 2.6 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 7.1/30.3 MB 2.6 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 7.9/30.3 MB 2.6 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 8.4/30.3 MB 2.6 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 8.9/30.3 MB 2.6 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 9.4/30.3 MB 2.6 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 10.2/30.3 MB 2.6 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 10.7/30.3 MB 2.6 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 11.0/30.3 MB 2.7 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 11.5/30.3 MB 2.7 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 11.5/30.3 MB 2.7 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 11.5/30.3 MB 2.7 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 11.8/30.3 MB 2.4 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 11.8/30.3 MB 2.4 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 11.8/30.3 MB 2.4 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 12.1/30.3 MB 2.2 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 12.1/30.3 MB 2.2 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 12.3/30.3 MB 2.0 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 12.3/30.3 MB 2.0 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 12.3/30.3 MB 2.0 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 12.6/30.3 MB 1.9 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 13.4/30.3 MB 1.9 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 13.9/30.3 MB 1.9 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 14.7/30.3 MB 2.0 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 15.2/30.3 MB 2.0 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 16.0/30.3 MB 2.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 16.5/30.3 MB 2.1 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 17.0/30.3 MB 2.1 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 17.6/30.3 MB 2.1 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 18.1/30.3 MB 2.1 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 18.4/30.3 MB 2.1 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 19.1/30.3 MB 2.1 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 19.7/30.3 MB 2.1 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 20.4/30.3 MB 2.2 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 21.0/30.3 MB 2.2 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 21.8/30.3 MB 2.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 22.3/30.3 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 22.8/30.3 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 23.3/30.3 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 24.1/30.3 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 24.9/30.3 MB 2.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 25.4/30.3 MB 2.3 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 26.2/30.3 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 26.7/30.3 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 27.5/30.3 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 28.0/30.3 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 28.8/30.3 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 29.4/30.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.9/30.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 30.3/30.3 MB 2.4 MB/s  0:00:12\n",
      "Downloading tiktoken-0.11.0-cp312-cp312-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.3 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 524.3/884.3 kB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 884.3/884.3 kB 3.3 MB/s  0:00:00\n",
      "Downloading regex-2025.7.34-cp312-cp312-win_amd64.whl (275 kB)\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml): started\n",
      "  Building wheel for openai-whisper (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=804013 sha256=6699ea0e046ee5401e797d717258ec119f34a4fcd87ced8739595926977622cd\n",
      "  Stored in directory: c:\\users\\pal\\appdata\\local\\pip\\cache\\wheels\\61\\d2\\20\\09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: regex, more-itertools, llvmlite, tiktoken, numba, openai-whisper\n",
      "\n",
      "   ---------------------------------------- 0/6 [regex]\n",
      "   ------ --------------------------------- 1/6 [more-itertools]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   ------------- -------------------------- 2/6 [llvmlite]\n",
      "   -------------------- ------------------- 3/6 [tiktoken]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   -------------------------- ------------- 4/6 [numba]\n",
      "   --------------------------------- ------ 5/6 [openai-whisper]\n",
      "   --------------------------------- ------ 5/6 [openai-whisper]\n",
      "   --------------------------------- ------ 5/6 [openai-whisper]\n",
      "   ---------------------------------------- 6/6 [openai-whisper]\n",
      "\n",
      "Successfully installed llvmlite-0.44.0 more-itertools-10.7.0 numba-0.61.2 openai-whisper-20250625 regex-2025.7.34 tiktoken-0.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script whisper.exe is installed in 'C:\\Users\\Pal\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c04e80d-20dc-4f69-be50-b80a93127837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Whisper model 'base'...\n",
      "Model loaded successfully.\n",
      "Transcribing 'C:\\Users\\Pal\\Downloads\\Telegram Desktop\\vinh.mp4'...\n",
      "\n",
      "--- Transcription Result ---\n",
      " If you don't get good at small talk, it's very difficult to get good at big talk. Small talk is just a way to warm up the conversation. Otherwise, you become that person that ends up going, hey, what is the meaning of life? As the first question when you meet somebody new. You don't start all conversations. I don't start all conversations. You do. I think to take it. So again, I think understand the context of why small talk is important, because often people tend to look at small talk and go, I don't want to do small talk. It's I think small talk is an art form that leads to deeper and more meaningful conversations. In the forefront of your mind, always have simple questions that you can ask other people that then can initiate small talk. I love asking people a simple question like this. Are you watching any shows at the moment on Netflix? And if they do, and I happen to watch it too, boom, how some fire, we start with something small like that. Another one I love to do is also like to ask people, what do you do with your free time? And that one just opens up a whole massive can of worms that then just leads to great conversations that gradually leads to those deeper conversations. And there's another simple one I'll give you. This one is a game I call high low buffalo, where high is something that's going well for you. Low is something that you're a little bit bummed out about in life. And buffalo is something interesting about you. And then when you are in a group of new people and you play high low buffalo, oh man, it creates vulnerability, connection, intrigue, because of the interesting thing, vulnerability, because of the thing that you kind of bummed out about. And the high, the thing that's going well for you, it just creates this wonderful chemistry. There's a bunch of little strategies there for you, but understand why we're doing this. Is this gradually leads to much bigger conversations?\n",
      "\n",
      "Transcript saved to 'transcript.txt'\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "# Replace 'your_audio_file.mp3' with the path to your audio file.\n",
    "# You can use .mp3, .wav, .m4a, or other common audio/video formats.\n",
    "audio_path = r\"C:\\Users\\Pal\\Downloads\\Telegram Desktop\\vinh.mp4\"\n",
    "\n",
    "# Choose a Whisper model.\n",
    "# The 'base' model is a good balance of speed and accuracy.\n",
    "# Other options: 'tiny', 'small', 'medium', 'large'\n",
    "model_size = 'base'\n",
    "\n",
    "# --- Main Script ---\n",
    "\n",
    "# Check if the audio file exists\n",
    "if not os.path.exists(audio_path):\n",
    "    print(f\"Error: The file '{audio_path}' was not found.\")\n",
    "else:\n",
    "    print(f\"Loading Whisper model '{model_size}'...\")\n",
    "    try:\n",
    "        model = whisper.load_model(model_size)\n",
    "        print(\"Model loaded successfully.\")\n",
    "        \n",
    "        print(f\"Transcribing '{audio_path}'...\")\n",
    "        # Transcribe the audio file\n",
    "        result = model.transcribe(audio_path, fp16=False)\n",
    "        \n",
    "        # Print the full transcript\n",
    "        print(\"\\n--- Transcription Result ---\")\n",
    "        print(result[\"text\"])\n",
    "        \n",
    "        # Optional: Save the transcript to a text file\n",
    "        output_file_path = \"transcript.txt\"\n",
    "        with open(output_file_path, \"w\") as f:\n",
    "            f.write(result[\"text\"])\n",
    "        print(f\"\\nTranscript saved to '{output_file_path}'\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d21cd748-b081-413c-b2cd-8ab9c9160e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript loaded successfully. Preparing for translation...\n",
      "\n",
      "--- Translation Result ---\n",
      "Original Text:\n",
      " If you don't get good at small talk, it's very difficult to get good at big talk. Small talk is just a way to warm up the conversation. Otherwise, you become that person that ends up going, hey, what is the meaning of life? As the first question when you meet somebody new. You don't start all conversations. I don't start all conversations. You do. I think to take it. So again, I think understand the context of why small talk is important, because often people tend to look at small talk and go, I don't want to do small talk. It's I think small talk is an art form that leads to deeper and more meaningful conversations. In the forefront of your mind, always have simple questions that you can ask other people that then can initiate small talk. I love asking people a simple question like this. Are you watching any shows at the moment on Netflix? And if they do, and I happen to watch it too, boom, how some fire, we start with something small like that. Another one I love to do is also like to ask people, what do you do with your free time? And that one just opens up a whole massive can of worms that then just leads to great conversations that gradually leads to those deeper conversations. And there's another simple one I'll give you. This one is a game I call high low buffalo, where high is something that's going well for you. Low is something that you're a little bit bummed out about in life. And buffalo is something interesting about you. And then when you are in a group of new people and you play high low buffalo, oh man, it creates vulnerability, connection, intrigue, because of the interesting thing, vulnerability, because of the thing that you kind of bummed out about. And the high, the thing that's going well for you, it just creates this wonderful chemistry. There's a bunch of little strategies there for you, but understand why we're doing this. Is this gradually leads to much bigger conversations?\n",
      "\n",
      "Translated Text (French):\n",
      "Si tu ne deviens bon à la petite chat, il est très difficile de becoming bon à la grande chat.\n",
      "La petite chat est juste une façon d'ouvrir le conversation. De l'autre, vous devriez être que personne qui finit par dire, hey, qu'est-ce la signification de la vie?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# --- Configuration ---\n",
    "# The path to the transcript file created by the previous script.\n",
    "transcript_path = \"transcript.txt\"\n",
    "\n",
    "# Set your target language for the translation.\n",
    "target_language = \"French\" # Change this to your desired language (e.g., \"French\", \"Spanish\")\n",
    "\n",
    "# --- API Configuration ---\n",
    "# This is a generic setup. You will need to modify this section\n",
    "# to match the specific API of the model you are using.\n",
    "\n",
    "# For OLLama (running locally):\n",
    "# You must have the OLLama server running and the desired model pulled.\n",
    "# Example command: ollama pull qwen\n",
    "api_url = \"http://localhost:11434/api/generate\"\n",
    "api_key = \"\" # OLLama does not require an API key by default\n",
    "\n",
    "# For DeepSeek or Qwen (via a hosted API):\n",
    "# You would get this URL and key from their official documentation.\n",
    "# api_url = \"https://api.deepseek.com/chat/completions\"\n",
    "# api_key = \"YOUR_DEEPSEEK_API_KEY\" # Replace with your actual API key\n",
    "\n",
    "# For Qwen via Alibaba Cloud DashScope:\n",
    "# api_url = \"https://dashscope-intl.aliyuncs.com/compatible-mode/v1/chat/completions\"\n",
    "# api_key = \"YOUR_DASHSCOPE_API_KEY\" # Replace with your actual API key\n",
    "\n",
    "\n",
    "# --- Main Script ---\n",
    "\n",
    "# Check if the transcript file exists.\n",
    "if not os.path.exists(transcript_path):\n",
    "    print(f\"Error: The transcript file '{transcript_path}' was not found.\")\n",
    "else:\n",
    "    try:\n",
    "        # Read the transcript from the file.\n",
    "        with open(transcript_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            transcript_text = f.read()\n",
    "\n",
    "        print(\"Transcript loaded successfully. Preparing for translation...\")\n",
    "\n",
    "        # Construct the API payload.\n",
    "        # This is an example payload. It may need to be adjusted based on the model's requirements.\n",
    "        payload = {\n",
    "            \"model\": \"qwen\", # Use the model name you have pulled with OLLama or specified by the API.\n",
    "            \"prompt\": f\"Translate the following text to {target_language}:\\n\\n{transcript_text}\",\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        # Set the headers for the API request.\n",
    "        # DeepSeek and Qwen often use the 'Authorization' header with a Bearer token.\n",
    "        # OLLama's local server typically does not need this.\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {api_key}\"\n",
    "        }\n",
    "\n",
    "        # Make the API call.\n",
    "        # OLLama might not need the headers.\n",
    "        if api_key:\n",
    "            response = requests.post(api_url, headers=headers, data=json.dumps(payload))\n",
    "        else:\n",
    "            response = requests.post(api_url, data=json.dumps(payload))\n",
    "            \n",
    "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
    "\n",
    "        result_json = response.json()\n",
    "        \n",
    "        # This part depends on the API's response structure.\n",
    "        # For OLLama, the translated text is often directly in 'response'.\n",
    "        # For other APIs, it might be nested, e.g., result_json['choices'][0]['message']['content']\n",
    "        \n",
    "        translated_text = result_json.get(\"response\", \"Could not find translation in the response.\")\n",
    "\n",
    "        print(\"\\n--- Translation Result ---\")\n",
    "        print(f\"Original Text:\\n{transcript_text}\\n\")\n",
    "        print(f\"Translated Text ({target_language}):\\n{translated_text}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An API request error occurred: {e}\")\n",
    "        print(\"Please check your API URL, API key, and network connection.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e16820b-f762-4948-9871-cd94b1315796",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd path/to/your/notebook_folder\n",
    "git init\n",
    "git add your_notebook.ipynb\n",
    "git commit -m \"Add notebook\"\n",
    "git remote add origin https://github.com/yourusername/your-repo-name.git\n",
    "git push -u origin master\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
